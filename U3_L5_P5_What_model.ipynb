{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: what model can answer this question?\n",
    "Estimated Time: 2-3 hours\n",
    "\n",
    "You now have a fairly substantial starting toolbox of supervised learning methods that you can use to tackle a host of exciting problems. To make sure all of these ideas are organized in your mind, please go through the list of problems below. For each, identify which supervised learning method(s) would be best for addressing that particular problem. Explain your reasoning and discuss your answers with your mentor.\n",
    "\n",
    "1. Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "2. You have more features (columns) than rows in your dataset.\n",
    "3. Identify the most important characteristic predicting likelihood of being jailed before age 20.\n",
    "4. Implement a filter to “highlight” emails that might be important to the recipient\n",
    "5. You have 1000+ features.\n",
    "6. Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "7. Your dataset dimensions are 982400 x 500\n",
    "8. Identify faces in an image.\n",
    "9. Predict which of three flavors of ice cream will be most popular with boys vs girls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "\n",
    "I would start with linear regression because it is a regression problem. I would us Lasso or Ridge Regression if I find my solutions are overfitting. Linear regression assumes that all the variables are multivariate normal.  Some feature engineering may be required to use this.  \n",
    "\n",
    "If there are too many features, don't use OLS or SVM.  Ridge regression is faster than Lasso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. You have more features (columns) than rows in your dataset.\n",
    "Use Lasso (L1) Regularization.  Lasso Regression inherently includes feature reduction.\n",
    "\n",
    "Random forest can also work, it looks at the features one at a time.\n",
    "\n",
    "Alternatively, could use PCA or possibly look at the correlation matrix and drop some features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identify the most important characteristic predicting likelihood of being jailed before age 20.\n",
    "\n",
    "Use a tree or forest of trees and look at the feature importances from the model.\n",
    "\n",
    "Could also use logistic regression to predict jailed or not jailed and look at the odds ratios for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implement a filter to “highlight” emails that might be important to the recipient\n",
    "Naive-Bayes text classifier.  Use key words to filter what would be important or from important senders.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. You have 1000+ features.\n",
    "Lasso Regression can inherently reduce features. Alternatively, can use feature selection before using a different model if it is a classification problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "There are a number of different models that could be used for this.  Logisic Regression could be used.  KNN, did other people with similar carts purchase the items.  A forest model is versatile and can be used.  A decision tree could also be used.  It would possibly be less accurate than the forest, but easier to interpret and take action on items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Your dataset dimensions are 982400 x 500\n",
    "My first approach would be to reduce features because 500 is a lot of features.  This could be done through knowledge of the problem, looking at correlation matrices or PCA.  The dataset it also large, so I would want to avoid using SVM or KNN since they are slow with large datasets.  I would possibly use a decision tree or random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Identify faces in an image.\n",
    "Support Vector Machines - better for a two class problem.\n",
    "KNN - looks for what images are most similar and groups together. \n",
    "This problem would be better addressed with neural networks, which haven't been covered by the Thinkful course yet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Predict which of three flavors of ice cream will be most popular with boys vs girls.\n",
    "Logistic Regression - perform for each flavor and can have percentages on most popular.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
